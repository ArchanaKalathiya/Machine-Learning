{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "An-fRHASiKgN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.layers import RepeatVector\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6q41jKyiMsx"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from CSV file\n",
    "data = pd.read_csv('dataset.csv')\n",
    "data.head(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AmLrDqEqjDkl"
   },
   "outputs": [],
   "source": [
    "# Convert the python code strings into a numerical representation using one-hot encoding\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(data)\n",
    "df = enc.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wCRk7K76jEnI"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_size = int(df.shape[0] * 0.8)\n",
    "X = df[:, :-1]\n",
    "y = df[:, -1].toarray().ravel()\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xIwVhaMpjSZZ"
   },
   "outputs": [],
   "source": [
    "# Define the Encoder-Decoder LSTM model\n",
    "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "encoder = LSTM(128)(inputs)\n",
    "decoder = RepeatVector(X_train.shape[1])(encoder)\n",
    "decoder = LSTM(128, return_sequences=True)(decoder)\n",
    "outputs = Dense(X_train.shape[2], activation='softmax')(decoder)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpSPu3H4knx9",
    "outputId": "66685cc0-3d56-4649-9936-d18462fe4654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "4/4 [==============================] - 10s 1s/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 2/90\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 3/90\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 4/90\n",
      "4/4 [==============================] - 3s 813ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 5/90\n",
      "4/4 [==============================] - 3s 839ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 6/90\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 7/90\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 8/90\n",
      "4/4 [==============================] - 3s 779ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 9/90\n",
      "4/4 [==============================] - 3s 819ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 10/90\n",
      "4/4 [==============================] - 4s 900ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 11/90\n",
      "4/4 [==============================] - 4s 912ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 12/90\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 13/90\n",
      "4/4 [==============================] - 3s 801ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 14/90\n",
      "4/4 [==============================] - 3s 800ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 15/90\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 16/90\n",
      "4/4 [==============================] - 3s 792ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 17/90\n",
      "4/4 [==============================] - 3s 810ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 18/90\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 19/90\n",
      "4/4 [==============================] - 3s 869ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 20/90\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 21/90\n",
      "4/4 [==============================] - 4s 901ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 22/90\n",
      "4/4 [==============================] - 3s 821ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 23/90\n",
      "4/4 [==============================] - 3s 854ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 24/90\n",
      "4/4 [==============================] - 3s 811ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 25/90\n",
      "4/4 [==============================] - 3s 820ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 26/90\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 27/90\n",
      "4/4 [==============================] - 3s 853ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 28/90\n",
      "4/4 [==============================] - 3s 869ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 29/90\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 30/90\n",
      "4/4 [==============================] - 3s 832ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 31/90\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 32/90\n",
      "4/4 [==============================] - 4s 971ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 33/90\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 34/90\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 35/90\n",
      "4/4 [==============================] - 4s 987ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 36/90\n",
      "4/4 [==============================] - 4s 968ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 37/90\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 38/90\n",
      "4/4 [==============================] - 4s 992ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 39/90\n",
      "4/4 [==============================] - 4s 905ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 40/90\n",
      "4/4 [==============================] - 4s 896ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 41/90\n",
      "4/4 [==============================] - 4s 906ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 42/90\n",
      "4/4 [==============================] - 4s 925ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 43/90\n",
      "4/4 [==============================] - 4s 908ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 44/90\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 45/90\n",
      "4/4 [==============================] - 4s 902ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 46/90\n",
      "4/4 [==============================] - 4s 888ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 47/90\n",
      "4/4 [==============================] - 4s 972ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 48/90\n",
      "4/4 [==============================] - 4s 966ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 49/90\n",
      "4/4 [==============================] - 4s 907ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 50/90\n",
      "4/4 [==============================] - 4s 897ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 51/90\n",
      "4/4 [==============================] - 4s 925ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 52/90\n",
      "4/4 [==============================] - 3s 855ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 53/90\n",
      "4/4 [==============================] - 4s 951ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 54/90\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 55/90\n",
      "4/4 [==============================] - 3s 892ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 56/90\n",
      "4/4 [==============================] - 3s 885ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 57/90\n",
      "4/4 [==============================] - 3s 879ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 58/90\n",
      "4/4 [==============================] - 3s 828ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 59/90\n",
      "4/4 [==============================] - 3s 833ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 60/90\n",
      "4/4 [==============================] - 3s 841ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 61/90\n",
      "4/4 [==============================] - 4s 908ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 62/90\n",
      "4/4 [==============================] - 3s 882ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 63/90\n",
      "4/4 [==============================] - 3s 819ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 64/90\n",
      "4/4 [==============================] - 3s 840ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 65/90\n",
      "4/4 [==============================] - 3s 827ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 66/90\n",
      "4/4 [==============================] - 3s 828ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 67/90\n",
      "4/4 [==============================] - 3s 842ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 68/90\n",
      "4/4 [==============================] - 3s 834ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 69/90\n",
      "4/4 [==============================] - 3s 827ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 70/90\n",
      "4/4 [==============================] - 3s 856ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 71/90\n",
      "4/4 [==============================] - 3s 837ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 72/90\n",
      "4/4 [==============================] - 3s 854ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 73/90\n",
      "4/4 [==============================] - 3s 839ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 74/90\n",
      "4/4 [==============================] - 3s 840ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 75/90\n",
      "4/4 [==============================] - 3s 844ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 76/90\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 77/90\n",
      "4/4 [==============================] - 3s 814ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 78/90\n",
      "4/4 [==============================] - 3s 832ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 79/90\n",
      "4/4 [==============================] - 3s 850ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 80/90\n",
      "4/4 [==============================] - 3s 819ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 81/90\n",
      "4/4 [==============================] - 3s 873ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 82/90\n",
      "4/4 [==============================] - 3s 848ms/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 83/90\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 0.9923 - val_loss: 0.9923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/90\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 85/90\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9923 - val_loss: 0.9923\n",
      "Epoch 86/90\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9923"
     ]
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "history = model.fit(X_train, X_train, epochs=90, validation_data=(X_test, X_test), batch_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGONyIFhkn-R",
    "outputId": "9be74f1f-217b-444e-8fbf-baa1728d661a"
   },
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model on the testing set\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "loss = model.evaluate(X_test, X_test)\n",
    "print(\"Test loss:\", loss)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy : \", accuracy)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "7tfNi46LkoC2",
    "outputId": "40eed5f9-4906-4bbe-86ae-1818774c30ab"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_test,'b',label='Original')\n",
    "plt.plot(y_pred,'r',label='Predicted')\n",
    "plt.title('Predicted and Original Values')\n",
    "plt.xlabel('Original')\n",
    "plt.ylabel('Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "riunFna9WCgC",
    "outputId": "7ceb6e1f-d168-4c70-bfeb-3e2d702e763f"
   },
   "outputs": [],
   "source": [
    "# Plot the training loss as a function of the number of epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAQn9izLWG2y",
    "outputId": "19aa941e-1d9c-445b-f2c7-d3d588618321"
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 score\", f1)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print(\"Precision score\", precision)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"Recall score\", recall)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix: \\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
